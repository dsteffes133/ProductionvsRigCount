{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11276423,"sourceType":"datasetVersion","datasetId":7049702},{"sourceId":11276711,"sourceType":"datasetVersion","datasetId":7049885},{"sourceId":11277680,"sourceType":"datasetVersion","datasetId":7050602}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-04T19:34:41.168199Z","iopub.execute_input":"2025-04-04T19:34:41.168523Z","iopub.status.idle":"2025-04-04T19:34:41.199850Z","shell.execute_reply.started":"2025-04-04T19:34:41.168499Z","shell.execute_reply":"2025-04-04T19:34:41.198773Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/northamericanrigcount/28-03-2025 North America Rig Count Report.xlsx\n/kaggle/input/prodfile/Production.xlsm\n/kaggle/input/weeklyproductionusa/BasicProductionCrudeWeekly.xlsx\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_pdf import PdfPages\n\ndef main():\n    \"\"\"\n    Master script that:\n    1) Loads rig data (weekly/daily) and merges sub-basin production data (monthly) from 2019+.\n    2) Loads separate weekly total US production data (EIA).\n    3) Generates:\n       - Historical rig count by basin chart\n       - Historical total US production (weekly EIA) chart\n       - Historical production by basin chart (excluding Prod_Total)\n       - Rig vs production by basin, with dual axes (2024+)\n       - Rig vs total production, dual axes (2024+)\n       - A table of 3-month and 6-month rig/production deltas for every basin\n       - A text page summarizing correlation findings\n    4) Exports all plots & tables to a single PDF.\n    \"\"\"\n\n    #==============================================================================\n    # 1) LOAD & PREPARE RIG DATA\n    #==============================================================================\n    rig_df = pd.read_excel(\n        '/kaggle/input/northamericanrigcount/28-03-2025 North America Rig Count Report.xlsx',\n        sheet_name='NAM Weekly',\n        usecols='A:L',\n        skiprows=10,\n        header=0\n    )\n    rig_df['US_PublishDate'] = pd.to_datetime(rig_df['US_PublishDate'])\n    rig_df = rig_df[rig_df['US_PublishDate'] >= \"2019-01-01\"].copy()\n\n    # Identify major basins vs. Other\n    major_basins = {'Williston', 'DJ-Niobrara', 'Eagle Ford', 'Permian'}\n    def unify_basin_rig(x):\n        return x if x in major_basins else 'Other'\n    rig_df['Basin'] = rig_df['Basin'].apply(unify_basin_rig)\n\n    # Group & pivot to columns = Rig_<Basin>\n    grouped_rig = rig_df.groupby(['US_PublishDate','Basin'], as_index=False)['Rig Count Value'].sum()\n    rig_pivot = grouped_rig.pivot(index='US_PublishDate', columns='Basin', values='Rig Count Value')\n    rig_pivot.columns = [f'Rig_{c}' for c in rig_pivot.columns]\n\n    # Daily forward-fill\n    full_rig_dates = pd.date_range(rig_pivot.index.min(), rig_pivot.index.max(), freq='D')\n    rig_pivot = rig_pivot.reindex(full_rig_dates).sort_index().ffill()\n\n    # Rig_Total\n    rig_pivot['Rig_Total'] = rig_pivot.sum(axis=1)\n\n    # Move index into a column\n    rig_pivot = rig_pivot.rename_axis('Date').reset_index()\n\n    #==============================================================================\n    # 2) LOAD & PREPARE SUB-BASIN PRODUCTION DATA\n    #==============================================================================\n    prod_df = pd.read_excel(\n        '/kaggle/input/prodfile/Production.xlsm',\n        sheet_name='Production (Regional)',\n        usecols='B:Y',\n        skiprows=4,\n        header=0\n    )\n    prod_df['Date (Month)'] = pd.to_datetime(prod_df['Date (Month)'])\n    prod_df = prod_df[prod_df['Date (Month)'] >= \"2019-01-01\"].copy()\n\n    basin_mapping = {\n        'Bakken': 'Williston',\n        'Niobrara': 'DJ-Niobrara',\n        'Eagle Ford': 'Eagle Ford',\n        'Permian': 'Permian'\n    }\n    def unify_basin_prod(x):\n        return basin_mapping[x] if x in basin_mapping else 'Other'\n    prod_df['Basin'] = prod_df['SBM Sub-Region'].apply(unify_basin_prod)\n\n    # Keep first row per (month, basin) in case of duplicates\n    monthly_prod = (\n        prod_df\n        .groupby(['Date (Month)', 'Basin'], as_index=False)['SBM Total (Mbpd)']\n        .agg('first')  \n    )\n    # Pivot => Prod_<Basin>\n    prod_pivot = monthly_prod.pivot(index='Date (Month)', columns='Basin', values='SBM Total (Mbpd)')\n    prod_pivot.columns = [f'Prod_{c}' for c in prod_pivot.columns]\n\n    # Daily reindex + forward fill\n    full_prod_dates = pd.date_range(prod_pivot.index.min(), prod_pivot.index.max(), freq='D')\n    prod_pivot = prod_pivot.reindex(full_prod_dates).sort_index().ffill()\n    prod_pivot['Prod_Total'] = prod_pivot.sum(axis=1)\n\n    prod_pivot = prod_pivot.rename_axis('Date').reset_index()\n\n    #==============================================================================\n    # 3) MERGE RIG & SUB-BASIN PRODUCTION\n    #==============================================================================\n    combined_df = pd.merge(rig_pivot, prod_pivot, on='Date', how='inner')\n\n    #==============================================================================\n    # 4) LOAD WEEKLY TOTAL US PRODUCTION (EIA) => df_production\n    #==============================================================================\n    df_production = pd.read_excel(\n        '/kaggle/input/weeklyproductionusa/BasicProductionCrudeWeekly.xlsx',\n        sheet_name='Data 1',\n        usecols='A:B',\n        skiprows=2,\n        header=0\n    )\n    df_production['Date'] = pd.to_datetime(df_production['Date'])\n    df_production = df_production[df_production['Date'] >= '2015-01-01'].copy()\n\n    #==============================================================================\n    # 5) BASIC ANALYSIS: CORRELATION, YOY, ETC.\n    #==============================================================================\n    # Correlation (same period) => Rig_Total vs. Prod_Total\n    corr_same_period = combined_df[['Rig_Total','Prod_Total']].corr().iloc[0,1]\n\n    # 3-month & 6-month forward shift\n    combined_df['Prod_3mAhead'] = combined_df['Prod_Total'].shift(-90)\n    combined_df['Prod_6mAhead'] = combined_df['Prod_Total'].shift(-180)\n    corr_3m_lag = combined_df[['Rig_Total','Prod_3mAhead']].corr().iloc[0,1]\n    corr_6m_lag = combined_df[['Rig_Total','Prod_6mAhead']].corr().iloc[0,1]\n\n    # YoY changes\n    combined_df['YoY Rig Change'] = combined_df['Rig_Total'] - combined_df['Rig_Total'].shift(365)\n    combined_df['YoY Prod Change'] = combined_df['Prod_Total'] - combined_df['Prod_Total'].shift(365)\n\n    #==============================================================================\n    # 6) DELTA TABLE FOR LAST 3 AND 6 MONTHS, PER BASIN\n    #==============================================================================\n    def get_nearest_value(df, date, col):\n        \"\"\"Return the value in `col` that's on or before `date`.\"\"\"\n        df_sub = df[df['Date'] <= date]\n        if df_sub.empty:\n            return np.nan\n        return df_sub.iloc[-1][col]\n\n    # We'll produce a row for each basin in [Williston, DJ-Niobrara, Eagle Ford, Permian, Other, 'Total']\n    basins_list = ['Williston','DJ-Niobrara','Eagle Ford','Permian','Other','Total']\n    \n    last_date = combined_df['Date'].max()\n    date_3m_ago = last_date - pd.DateOffset(months=3)\n    date_6m_ago = last_date - pd.DateOffset(months=6)\n\n    delta_rows = []\n    for basin in basins_list:\n        # Decide which columns to use\n        rig_col  = f'Rig_{basin}'  if basin != 'Total' else 'Rig_Total'\n        prod_col = f'Prod_{basin}' if basin != 'Total' else 'Prod_Total'\n\n        # Current rig / prod\n        rig_now  = get_nearest_value(combined_df, last_date, rig_col)\n        prod_now = get_nearest_value(combined_df, last_date, prod_col)\n\n        # 3 months rig / prod\n        rig_3m = get_nearest_value(combined_df, date_3m_ago, rig_col)\n        prod_3m = get_nearest_value(combined_df, date_3m_ago, prod_col)\n        rig_3m_delta = rig_now - rig_3m if pd.notnull(rig_now) and pd.notnull(rig_3m) else np.nan\n        prod_3m_delta = prod_now - prod_3m if pd.notnull(prod_now) and pd.notnull(prod_3m) else np.nan\n\n        # 6 months rig / prod\n        rig_6m = get_nearest_value(combined_df, date_6m_ago, rig_col)\n        prod_6m = get_nearest_value(combined_df, date_6m_ago, prod_col)\n        rig_6m_delta = rig_now - rig_6m if pd.notnull(rig_now) and pd.notnull(rig_6m) else np.nan\n        prod_6m_delta = prod_now - prod_6m if pd.notnull(prod_now) and pd.notnull(prod_6m) else np.nan\n\n        delta_rows.append({\n            'Basin': basin,\n            '3M Rig Δ': rig_3m_delta,\n            '3M Prod Δ (Mbpd)': prod_3m_delta,\n            '6M Rig Δ': rig_6m_delta,\n            '6M Prod Δ (Mbpd)': prod_6m_delta\n        })\n\n    delta_basin_df = pd.DataFrame(delta_rows)\n\n    #==============================================================================\n    # 7) CREATE PDF & PLOTS\n    #==============================================================================\n    with PdfPages('BasinProductionandRigCount.pdf') as pdf:\n\n        #\n        # 7.1) Historical Rig Count by Basin\n        #\n        fig1, ax1 = plt.subplots(figsize=(12,6))\n        rig_cols = [c for c in rig_pivot.columns if c.startswith('Rig_')]\n        for col in rig_cols:\n            ax1.plot(rig_pivot['Date'], rig_pivot[col], label=col)\n        ax1.set_title(\"Historical Rig Count by Basin (2019+)\")\n        ax1.set_xlabel(\"Date\")\n        ax1.set_ylabel(\"Rig Count\")\n        ax1.legend()\n        pdf.savefig(fig1)\n        plt.close(fig1)\n\n        #\n        # 7.2) Historical total US production (weekly EIA)\n        #\n        fig2, ax2 = plt.subplots(figsize=(12,6))\n        ax2.plot(df_production['Date'], df_production['Weekly U.S. Field Production of Crude Oil  (Thousand Barrels per Day)'])\n        ax2.set_title(\"Weekly US Field Production of Crude (2015+)\")\n        ax2.set_xlabel(\"Date\")\n        ax2.set_ylabel(\"Production (Thousand Barrels per Day)\")\n        pdf.savefig(fig2)\n        plt.close(fig2)\n\n        #\n        # 7.3) Historical production by basin (EXCLUDING Prod_Total)\n        #\n        fig3, ax3 = plt.subplots(figsize=(12,6))\n        # Grab all columns that start with 'Prod_' except 'Prod_Total'\n        prod_basin_cols = [c for c in prod_pivot.columns if c.startswith('Prod_') and c != 'Prod_Total']\n        for col in prod_basin_cols:\n            ax3.plot(prod_pivot['Date'], prod_pivot[col], label=col)\n        ax3.set_title(\"Historical Production by Basin (2019+)\")\n        ax3.set_xlabel(\"Date\")\n        ax3.set_ylabel(\"Production (Mbpd)\")\n        ax3.legend()\n        pdf.savefig(fig3)\n        plt.close(fig3)\n\n        #\n        # 7.4) Rig vs Production by Basin (2024+), dual axes\n        #\n        from_2024 = combined_df[combined_df['Date'] >= '2024-01-01'].copy()\n        basins_to_plot = ['Williston','DJ-Niobrara','Eagle Ford','Permian','Other']\n        for basin in basins_to_plot:\n            rig_col  = f'Rig_{basin}'\n            prod_col = f'Prod_{basin}'\n            if rig_col not in from_2024.columns or prod_col not in from_2024.columns:\n                continue\n\n            # Make sure there's actually data\n            df_basin = from_2024[['Date', rig_col, prod_col]].dropna()\n            if df_basin.empty:\n                continue\n\n            fig_basin, ax_basin_1 = plt.subplots(figsize=(12,6))\n            ax_basin_1.set_title(f\"{basin}: Rig Count vs. Production (2024+)\")\n            color1 = 'tab:blue'\n            ax_basin_1.set_xlabel(\"Date\")\n            ax_basin_1.set_ylabel(\"Rig Count\", color=color1)\n            ax_basin_1.plot(df_basin['Date'], df_basin[rig_col], color=color1, label='Rig Count')\n            ax_basin_1.tick_params(axis='y', labelcolor=color1)\n\n            ax_basin_2 = ax_basin_1.twinx()\n            color2 = 'tab:red'\n            ax_basin_2.set_ylabel(\"Production (Mbpd)\", color=color2)\n            ax_basin_2.plot(df_basin['Date'], df_basin[prod_col], color=color2, label='Production')\n            ax_basin_2.tick_params(axis='y', labelcolor=color2)\n\n            pdf.savefig(fig_basin)\n            plt.close(fig_basin)\n\n        #\n        # 7.5) Rig vs Production (Total), dual axes (2024+)\n        #\n        df_2024_total = from_2024[['Date','Rig_Total','Prod_Total']].dropna()\n        if not df_2024_total.empty:\n            fig5, ax5 = plt.subplots(figsize=(12,6))\n            ax5.set_title(\"Total Rig Count vs. Total Production (2024+)\")\n            ax5.set_xlabel(\"Date\")\n\n            color1 = 'tab:blue'\n            ax5.set_ylabel(\"Rig Count\", color=color1)\n            ax5.plot(df_2024_total['Date'], df_2024_total['Rig_Total'], color=color1, label='Rig Count')\n            ax5.tick_params(axis='y', labelcolor=color1)\n\n            ax5_2 = ax5.twinx()\n            color2 = 'tab:red'\n            ax5_2.set_ylabel(\"Production (Mbpd)\", color=color2)\n            ax5_2.plot(df_2024_total['Date'], df_2024_total['Prod_Total'], color=color2, label='Total Production')\n            ax5_2.tick_params(axis='y', labelcolor=color2)\n\n            pdf.savefig(fig5)\n            plt.close(fig5)\n\n        #\n        # 7.6) DELTA TABLE (3M, 6M) for all basins\n        #\n        fig_table = plt.figure(figsize=(10, 6))\n        fig_table.suptitle(\"3-Month and 6-Month Deltas per Basin\", fontsize=14, fontweight='bold')\n        ax_table = fig_table.add_subplot(111)\n        ax_table.axis('off')\n\n        # Build table data\n        table_data = []\n        for _, row in delta_basin_df.iterrows():\n            table_data.append([\n                row['Basin'],\n                f\"{row['3M Rig Δ']:.1f}\" if pd.notnull(row['3M Rig Δ']) else \"\",\n                f\"{row['3M Prod Δ (Mbpd)']:.1f}\" if pd.notnull(row['3M Prod Δ (Mbpd)']) else \"\",\n                f\"{row['6M Rig Δ']:.1f}\" if pd.notnull(row['6M Rig Δ']) else \"\",\n                f\"{row['6M Prod Δ (Mbpd)']:.1f}\" if pd.notnull(row['6M Prod Δ (Mbpd)']) else \"\"\n            ])\n\n        col_labels = [\"Basin\", \"3M Rig Δ\", \"3M Prod Δ (Mbpd)\", \"6M Rig Δ\", \"6M Prod Δ (Mbpd)\"]\n        table = ax_table.table(\n            cellText=table_data,\n            colLabels=col_labels,\n            loc='center'\n        )\n        table.auto_set_font_size(False)\n        table.set_fontsize(11)\n        table.scale(1, 1.5)  # Adjust table size as needed\n\n        pdf.savefig(fig_table)\n        plt.close(fig_table)\n\n        #\n        # 7.7) A TEXT PAGE WITH CORRELATION RESULTS & SUMMARY\n        #\n        summary_text = f\"\"\"\n        SUMMARY OF FINDINGS\n\n        1) Correlation (no lag) between total rig count and production: {corr_same_period:.3f}\n        2) Correlation (3-month forward production) vs rig count: {corr_3m_lag:.3f}\n        3) Correlation (6-month forward production) vs rig count: {corr_6m_lag:.3f}\n\n        Observations:\n        - Honestly not much correlation between rig count and basin production.\n        - Thought it was interesting to witness Permian rig count decreasing currently.\n        - Still production is at all time highs and only predicted to increase.\n        \"\"\"\n\n        fig_text = plt.figure(figsize=(8.5, 11))\n        fig_text.text(0.1, 0.9, summary_text, fontsize=12, va='top')\n        pdf.savefig(fig_text)\n        plt.close(fig_text)\n\n    # End of with => \"My_Oil_Analysis_Report.pdf\" is finalized\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T19:56:03.848481Z","iopub.execute_input":"2025-04-04T19:56:03.848907Z","iopub.status.idle":"2025-04-04T19:56:34.368164Z","shell.execute_reply.started":"2025-04-04T19:56:03.848877Z","shell.execute_reply":"2025-04-04T19:56:34.367169Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n  warn(msg)\n","output_type":"stream"}],"execution_count":12}]}